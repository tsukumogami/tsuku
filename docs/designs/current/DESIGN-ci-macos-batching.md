---
status: Current
problem: GitHub-hosted macOS runners have low concurrency limits (5 jobs vs 20 for Linux), causing queue saturation and 30+ minute delays when PRs touch many recipes.
decision: Aggregate macOS CI jobs into a single job per architecture that iterates over all changed items sequentially, reducing concurrent jobs from 170+ to 5 maximum.
rationale: This approach eliminates queue contention while remaining simple to implement and maintain. It ensures multiple workflows can run concurrently without exceeding runner limits, trading per-recipe visibility in the UI for dramatic improvements in total wall-clock time and developer experience.
---

# CI macOS Runner Batching Strategy

## Status

Current

## Context and Problem Statement

GitHub-hosted macOS runners have significantly lower concurrency limits than Linux runners. On the free tier, only 5 macOS jobs can run concurrently versus 20 Linux jobs. When PRs touch many recipes or golden files, the current per-recipe/per-file matrix strategy creates severe queue congestion.

Evidence from PR #858 demonstrates the problem:
- 85 macOS (darwin-arm64) jobs were queued simultaneously
- Linux jobs completed in ~10 minutes while macOS jobs remained queued for 30+ minutes
- The PR added golden files for 138 recipes, triggering validation for each on each platform
- Total wall-clock time to completion exceeded 60 minutes due to queue serialization

Four workflows are affected:
- `validate-golden-execution.yml` - Executes each changed golden file on its target platform
- `test-changed-recipes.yml` - Tests each changed recipe on Linux and macOS
- `test.yml` - Runs integration tests for a fixed set of tools on each platform
- `build-essentials.yml` - Tests build tooling (Homebrew, configure/make, cmake, meson) on all platforms

All four workflows use matrix strategy with `fail-fast: false`, spawning independent jobs per changed recipe/file. This provides excellent failure isolation but causes queue saturation for macOS.

### Scope

**In scope:**
- Batching strategy for macOS CI jobs in affected workflows
- Failure visibility approach when batching
- Implementation changes to workflow files

**Out of scope:**
- Linux runner optimization (no concurrency constraint)
- Self-hosted runner infrastructure
- darwin-amd64 (Intel Mac) support (requires paid tier)

## Decision Drivers

- **Concurrency constraint**: 5 concurrent macOS jobs on free tier
- **Cost**: macOS runners cost 10x more than Linux ($0.08/min vs $0.008/min)
- **Failure visibility**: Per-recipe visibility is valuable for debugging failures
- **PR throughput**: Long queue times impact developer experience
- **Workflow maintainability**: Solution should be understandable and maintainable

## Implementation Context

### Existing Patterns

**Affected workflows:**
- `validate-golden-execution.yml` (lines 241-277): Uses dynamic matrix from `detect-changes` job, spawns one job per golden file with `${{ matrix.os }}` runner
- `test-changed-recipes.yml` (lines 128-169): Uses static matrix with `${{ fromJson(needs.matrix.outputs.recipes) }}`, spawns separate jobs for Linux and macOS
- `test.yml` (lines 240-270): Uses matrix from `test-matrix.json`, spawns one job per tool on each platform
- `build-essentials.yml`: Uses hardcoded platform × tool matrix, spawns ~20 macOS jobs (10 Apple Silicon + 10 Intel)

**Similar implementations:**
- `deploy-recipes.yml`: Uses `concurrency:` to serialize Pages deployments (different problem)

**Conventions to follow:**
- Dynamic matrix generation via JSON from upstream `detect-changes` job
- Platform detection in shell scripts rather than workflow expressions where possible
- `fail-fast: false` to get complete results

### Applicable Specifications

**GitHub Actions Concurrency:**
- Free tier: 5 concurrent macOS jobs, 20 concurrent Linux jobs
- `max-parallel` keyword limits concurrent jobs within a matrix
- Dynamic matrix can be generated by upstream job using `fromJSON()`

**Batching Approach (from research):**
- No built-in "batch N items per job" feature
- Must implement batching in detect-changes job: group items into arrays
- Downstream job loops over array items within single job execution

### Research Summary

**Constraints:**
- 5 macOS concurrent jobs hard limit on free tier
- Current workflows spawn O(N) macOS jobs where N = changed recipes

**Patterns to follow:**
- Upstream job groups items into batches (JSON arrays of arrays)
- Matrix uses batch arrays, not individual items
- Downstream job iterates over batch items in shell script

**Key decision:**
- Trade per-job granularity for reduced job count
- Failure output becomes batch-level rather than item-level

## Considered Options

### Option 1: Fixed Batch Size

Group macOS jobs into fixed-size batches (e.g., 10 recipes per job). The detect-changes job partitions items into arrays of up to N items, and each macOS job loops over its batch.

**Example:** 85 recipes becomes 9 batches of ~10 each = 9 macOS jobs instead of 85.

**Pros:**
- Simple to implement - straightforward shell script partitioning
- Predictable job count regardless of PR size
- Easy to tune batch size based on experience

**Cons:**
- Fixed size may be suboptimal for varying PR sizes (small PRs still spawn multiple jobs)
- Job names become batch indices, losing recipe names in GitHub UI
- Single batch failure hides which specific recipe failed until viewing logs

### Option 2: max-parallel Throttling

Keep per-recipe jobs but add `max-parallel: 5` to the matrix strategy. GitHub queues jobs internally rather than spawning all at once.

**Pros:**
- Minimal workflow change - single line addition
- Preserves per-recipe job visibility in GitHub UI
- GitHub handles queuing internally

**Cons:**
- Does not reduce total job count - 85 jobs still spawn
- Queue time may not improve: GitHub already throttles based on runner availability, making this largely redundant
- Does not address the underlying scalability issue
- Jobs remain queued in GitHub UI, creating visual noise

**Note:** This option is included for completeness but does not meaningfully solve the problem since GitHub's runner allocation already implements similar throttling at the infrastructure level.

### Option 3: Single Aggregated macOS Job

Replace the macOS matrix with a single job that runs all changed recipes sequentially.

**Pros:**
- Maximum reduction in job count (always 1 macOS job)
- Simplest implementation - no batching logic needed
- Complete results in single job output

**Cons:**
- Sequential execution significantly increases total time for large PRs
- Single failure can abort entire job (mitigatable with `set +e` and error aggregation)
- No parallelism benefit even when runners are available
- Job timeout risk for large PRs (10-minute job limit per recipe, ~15 hours for 85 recipes)

### Option 4: Adaptive Batching

Dynamically calculate batch size based on number of changed items. Target a maximum job count (e.g., 5 macOS jobs) and divide items evenly.

**Example:** 85 recipes / 5 jobs = 17 recipes per batch.

**Pros:**
- Optimizes for concurrency limit regardless of PR size
- Small PRs may run with fewer jobs (ceil(items/batch_size))
- Scales proportionally with PR size

**Cons:**
- More complex batch calculation logic
- Variable batch sizes make job duration unpredictable
- Still loses per-recipe visibility in GitHub UI

### Option 5: Hybrid Approach

Apply batching only when item count exceeds a threshold. Below threshold, use per-recipe jobs; above threshold, switch to adaptive batching.

**Example:** If items <= 10, per-recipe jobs; if items > 10, batch to ~5 jobs.

**Pros:**
- Preserves per-recipe visibility for small PRs (most common case)
- Batches only when necessary (large PRs)
- Best of both worlds for typical usage patterns

**Cons:**
- Most complex implementation - conditional logic in workflow
- Two code paths to maintain and test
- Threshold tuning requires experimentation

## Evaluation Against Decision Drivers

| Option | Concurrency Constraint | Cost | Failure Visibility | PR Throughput | Maintainability |
|--------|----------------------|------|-------------------|---------------|-----------------|
| 1. Fixed Batch | Good (reduces to ~N jobs) | Good | Poor (batch-level) | Good | Good |
| 2. max-parallel | Poor (no reduction) | Poor (same jobs) | Good (per-recipe) | Fair | Excellent |
| **3. Single Job/Arch** | **Excellent (1 job/arch)** | **Excellent** | **Fair (log groups)** | **Good** | **Excellent** |
| 4. Adaptive | Good (targets 5 jobs) | Good | Poor (batch-level) | Good | Fair |
| 5. Hybrid | Good (batches when needed) | Good | Good (small PRs) / Poor (large) | Good | Poor |

**Note:** Option 3 (Single Job Per Architecture) is the chosen approach. Cross-workflow safety (3 workflows × 1 job + 1 workflow × 2 jobs = 5 jobs) makes this preferable to adaptive batching which would need coordination between workflows.

## Uncertainties

- **Actual queue wait times:** We observed ~60 minute total time in PR #858 but don't have data on typical queue behavior
- **Batch failure rates:** Unknown whether batch failures are common enough to matter
- **Typical PR size distribution:** We don't know what percentage of PRs touch >10 recipes
- **Log inspection workflow:** Unclear how often developers need per-recipe failure visibility vs accepting batch-level

## Assumptions

- **Recipe tests are independent:** Tests can run in any order without affecting results
- **macOS testing necessary for all recipes:** Cannot filter to only recipes with darwin support (though many are Linux-only)
- **Free tier constraint is fixed:** Upgrading to paid tier is not considered (5 vs 50 concurrent macOS jobs)
- **CI feedback timing is critical:** Developers wait for CI results rather than context-switching

## Decision Outcome

**Chosen option: Single Job Per Architecture (variant of Option 3)**

Each workflow spawns at most one macOS job per architecture. Three workflows test only darwin-arm64 (1 job each), while build-essentials tests both darwin-arm64 and darwin-amd64 (2 jobs). With four affected workflows, the maximum is 5 macOS jobs matching the 5 runner limit.

### Rationale

This option was chosen because:
- **Simplicity:** No batch calculation logic needed - just aggregate items by architecture
- **Cross-workflow safety:** Multiple workflows can run concurrently without exceeding runner limits (5 jobs = 5 runners)
- **Future-proof:** If darwin-amd64 is enabled for all workflows, each would have 2 jobs (one per arch), totaling 8 jobs which would need attention
- **Reduced risk:** Simpler implementation means fewer edge cases and easier debugging

Alternatives were rejected because:
- **Option 1 (Fixed Batch):** Unnecessary complexity when single-job-per-arch is sufficient
- **Option 2 (max-parallel):** Does not reduce job count; essentially redundant with GitHub's existing throttling
- **Option 4 (Adaptive Batching):** More complex than needed; doesn't account for cross-workflow interaction
- **Option 5 (Hybrid):** Adds unnecessary complexity with two code paths for marginal benefit

### Trade-offs Accepted

By choosing this option, we accept:
- **Loss of per-recipe visibility:** Failures appear at job level in GitHub UI; developers must inspect logs to identify specific failing recipe
- **Sequential execution within job:** All darwin-arm64 items run sequentially in one job
- **Longer individual job duration:** Single macOS job runs longer than current per-recipe jobs

These are acceptable because:
- Per-recipe failures in macOS CI are relatively rare (most failures are caught in Linux runs)
- Sequential execution is simpler and avoids cross-workflow resource contention
- Total wall-clock time improves: 5 jobs (from 4 workflows) vs 170+ jobs queued for 5 runners

## Solution Architecture

### Overview

The solution modifies four workflow files to aggregate macOS items into a single job per architecture:

1. **detect-changes job:** Groups all darwin items by architecture (currently only darwin-arm64)
2. **macOS test job:** Single job iterates over all items for that architecture
3. **Linux test job:** Unchanged - continues per-recipe execution (no concurrency constraint)

### Components

```
┌─────────────────────────────────────────────────────────────┐
│                    detect-changes job                        │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────────┐ │
│  │ Get changed │ -> │ Filter by   │ -> │ Group by        │ │
│  │ files       │    │ platform    │    │ architecture    │ │
│  └─────────────┘    └─────────────┘    └─────────────────┘ │
│                                                             │
│  Outputs:                                                   │
│  - linux_matrix: per-recipe (unchanged)                     │
│  - macos_items: all darwin-arm64 items as single array      │
│  - has_macos: boolean (skip job if empty)                   │
└─────────────────────────────────────────────────────────────┘
                           │
           ┌───────────────┴───────────────┐
           ▼                               ▼
┌───────────────────────┐    ┌───────────────────────────────┐
│  Linux test jobs      │    │     macOS test job            │
│  (per-recipe matrix)  │    │     (single job per arch)     │
│                       │    │                               │
│  N jobs total         │    │  1 job (darwin-arm64)         │
│  (no change)          │    │  Iterates over all items      │
└───────────────────────┘    └───────────────────────────────┘
```

### Key Interfaces

**Output Format:**

```json
{
  "macos_items": ["recipe1", "recipe2", "recipe3", ...],
  "has_macos": true
}
```

**Job Configuration:**

```yaml
test-macos:
  name: "macOS (darwin-arm64)"
  needs: detect-changes
  if: needs.detect-changes.outputs.has_macos == 'true'
  runs-on: macos-latest
```

### Data Flow

1. `detect-changes` job runs on ubuntu-latest
2. Identifies changed recipes/golden files
3. Splits items by platform (linux vs darwin)
4. Linux items: output as-is for per-recipe matrix
5. Darwin items: output as single array for aggregated job
6. Single macOS job iterates over all items sequentially

### Job Iteration Pattern

```yaml
- name: "Test all macOS recipes"
  run: |
    FAILED=()
    ITEMS='${{ needs.detect-changes.outputs.macos_items }}'
    CACHE_DIR="${{ runner.temp }}/tsuku-cache/downloads"
    mkdir -p "$CACHE_DIR"

    for recipe in $(echo "$ITEMS" | jq -r '.[]'); do
      echo "::group::Testing $recipe"

      # Fresh TSUKU_HOME per recipe with shared download cache
      export TSUKU_HOME="${{ runner.temp }}/tsuku-$recipe"
      mkdir -p "$TSUKU_HOME/cache"
      ln -s "$CACHE_DIR" "$TSUKU_HOME/cache/downloads"

      if ! ./tsuku install --force "$recipe"; then
        FAILED+=("$recipe")
      fi
      echo "::endgroup::"
    done

    # Report failures at end (don't fail fast)
    if [ ${#FAILED[@]} -gt 0 ]; then
      echo "::error::Failed recipes: ${FAILED[*]}"
      exit 1
    fi
```

**State isolation between recipes:**
- Each recipe gets a fresh `$TSUKU_HOME` directory (e.g., `/tmp/tsuku-kubectl`)
- Download cache is shared via symlink for speed
- No cleanup logic needed - complete isolation by design
- Each recipe installs as if on a fresh system

**Error handling semantics:**
- Recipe failures do NOT abort the job (continue to next recipe)
- All failures collected and reported at job end
- Job exits non-zero if any recipe failed
- GitHub UI shows job failure; log groups reveal specific failures

## Implementation Approach

### Phase 1: Workflow Changes

Update all four affected workflows to aggregate macOS items:

**For `test-changed-recipes.yml`:**
- Modify `matrix` job to output `macos_items` array and `has_macos` boolean
- Replace `test-macos` matrix job with single aggregated job
- Add iteration loop with `::group::` markers for visibility

**For `validate-golden-execution.yml`:**
- Modify `detect-changes` job to separate darwin items from matrix
- Replace per-file macOS execution with single aggregated job
- Keep Linux execution unchanged (per-file matrix)

**For `test.yml`:**
- Replace `integration-macos` matrix job with single aggregated job
- Iterate over all macOS tests from `test-matrix.json`
- Keep Linux execution unchanged (per-test matrix)

**For `build-essentials.yml`:**
- Split existing jobs into Linux-only versions (keep per-tool matrix)
- Add two aggregated macOS jobs: `test-macos-arm64` and `test-macos-intel`
- Each macOS job runs all tool tests sequentially with isolated TSUKU_HOME

### Phase 2: Testing and Rollout

- Test with a PR that touches multiple recipes
- Verify macOS job processes all items
- Confirm failure visibility via log groups is acceptable
- Monitor queue times before/after

## Security Considerations

### Download Verification

**Not applicable** - This design changes CI workflow orchestration (how jobs are scheduled), not download behavior. The actual recipe execution (`tsuku install`) remains unchanged and continues to use existing checksum verification.

### Execution Isolation

**No change** - The security boundary for each job remains the same:
- Each macOS job runs in an isolated GitHub-hosted runner VM
- Jobs have access to repository code and GITHUB_TOKEN (unchanged)
- Batching multiple recipes into one job does not increase the attack surface since all recipes would have access to the same secrets in either model

### Supply Chain Risks

**No new risks introduced** - This design does not change:
- Where recipes come from (repository)
- How recipes are validated
- What gets downloaded and executed

The batching logic itself runs in shell within the workflow file, using only standard utilities (`jq`, shell arithmetic). No external dependencies are added.

### User Data Exposure

**Not applicable** - This design operates entirely within GitHub Actions CI. No user data is accessed or transmitted beyond what already occurs in CI runs.

### Mitigations

| Risk | Mitigation | Residual Risk |
|------|------------|---------------|
| Batch script injection | Recipes are from same repository; no external input to batch logic | None - controlled environment |
| Cross-contamination between recipes | Fresh `$TSUKU_HOME` per recipe; only download cache shared | None - complete isolation |
| Dependency masking (shared deps) | Fresh `$TSUKU_HOME` ensures each recipe must declare all dependencies | None |
| Longer job duration exposing secrets | GITHUB_TOKEN expiration unchanged; job timeout still applies | None |

### Summary

This is a CI orchestration change that reduces the number of macOS jobs without modifying the security properties of individual recipe execution. The trust model, isolation boundaries, and verification mechanisms remain unchanged.

## Consequences

### Positive

- **Eliminated queue contention:** 5 macOS jobs (one per workflow) vs 170+ jobs competing for 5 runners
- **Lower job overhead:** Single job amortizes checkout, Go setup, tsuku build across all items
- **Simpler GitHub UI:** 5 macOS jobs instead of 170+ makes PR checks easy to scan
- **Cross-workflow safety:** Multiple workflows can run concurrently without exceeding runner limits
- **Simpler implementation:** No batch calculation logic needed

### Negative

- **Reduced failure granularity:** Must inspect logs to find specific failing recipe
- **Longer individual jobs:** Single macOS job runs longer (all items sequential)
- **No parallelism within architecture:** Items within darwin-arm64 run sequentially

### Mitigations

- **Failure granularity:** Use `::group::` markers for each recipe, report all failures at end
  ```bash
  echo "::group::Testing $recipe"
  ./tsuku install --force "$recipe"
  echo "::endgroup::"
  ```
- **Longer jobs:** Acceptable trade-off; total wall-clock time decreases dramatically
- **No parallelism:** Sequential execution is simpler and sufficient given reduced queue time
