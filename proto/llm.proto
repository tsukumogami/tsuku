syntax = "proto3";

package tsuku.llm.v1;

option go_package = "github.com/tsukumogami/tsuku/internal/llm/proto";

// InferenceService provides local LLM inference capabilities.
// The server runs as a separate process (tsuku-llm) and communicates
// over Unix domain sockets.
service InferenceService {
  // Complete generates a completion for the given request.
  // Supports tool calling for structured extraction tasks.
  rpc Complete(CompletionRequest) returns (CompletionResponse);

  // Shutdown gracefully terminates the inference server.
  // Called when tsuku exits or when idle timeout is reached.
  rpc Shutdown(ShutdownRequest) returns (ShutdownResponse);

  // GetStatus returns the current server status including loaded model info.
  rpc GetStatus(StatusRequest) returns (StatusResponse);
}

// CompletionRequest contains the input for an inference request.
message CompletionRequest {
  // System prompt providing context for the model.
  string system_prompt = 1;

  // Conversation history.
  repeated Message messages = 2;

  // Available tools the model can call.
  repeated ToolDef tools = 3;

  // Maximum tokens to generate.
  int32 max_tokens = 4;

  // Optional JSON schema to constrain output format.
  // Used for structured extraction tasks.
  string json_schema = 5;
}

// CompletionResponse contains the model's output.
message CompletionResponse {
  // Text content generated by the model.
  string content = 1;

  // Tool calls requested by the model.
  repeated ToolCall tool_calls = 2;

  // Reason the model stopped generating.
  // Values: "end_turn", "tool_use", "max_tokens"
  string stop_reason = 3;

  // Token usage statistics.
  Usage usage = 4;
}

// Message represents a single turn in the conversation.
message Message {
  // Role of the message author.
  Role role = 1;

  // Text content of the message.
  string content = 2;

  // Tool calls made in this message (for assistant messages).
  repeated ToolCall tool_calls = 3;

  // Tool result (for tool messages).
  ToolResult tool_result = 4;
}

// Role indicates who authored a message.
enum Role {
  ROLE_UNSPECIFIED = 0;
  ROLE_USER = 1;
  ROLE_ASSISTANT = 2;
  ROLE_TOOL = 3;
}

// ToolDef defines a tool available to the model.
message ToolDef {
  // Unique name of the tool.
  string name = 1;

  // Human-readable description of what the tool does.
  string description = 2;

  // JSON Schema defining the tool's parameters.
  // Encoded as JSON string for flexibility.
  string parameters_schema = 3;
}

// ToolCall represents a request from the model to invoke a tool.
message ToolCall {
  // Unique identifier for this tool call.
  string id = 1;

  // Name of the tool to invoke.
  string name = 2;

  // Arguments to pass to the tool, encoded as JSON.
  string arguments_json = 3;
}

// ToolResult contains the output from a tool invocation.
message ToolResult {
  // ID of the tool call this result corresponds to.
  string tool_call_id = 1;

  // Output from the tool, typically as string or JSON.
  string content = 2;

  // Whether the tool invocation failed.
  bool is_error = 3;
}

// Usage tracks token consumption for billing/monitoring.
message Usage {
  // Number of tokens in the input (prompt + history).
  int32 input_tokens = 1;

  // Number of tokens generated.
  int32 output_tokens = 2;
}

// ShutdownRequest signals the server to terminate.
message ShutdownRequest {
  // If true, wait for any in-flight requests to complete.
  bool graceful = 1;
}

// ShutdownResponse acknowledges shutdown initiation.
message ShutdownResponse {
  // True if shutdown was accepted.
  bool accepted = 1;
}

// StatusRequest queries the server's current state.
message StatusRequest {}

// StatusResponse provides server health and model information.
message StatusResponse {
  // Whether the server is ready to accept requests.
  bool ready = 1;

  // Currently loaded model name (e.g., "qwen2.5-1.5b-q4_k_m").
  string model_name = 2;

  // Model file size in bytes.
  int64 model_size_bytes = 3;

  // Hardware backend in use (e.g., "cuda", "metal", "cpu").
  string backend = 4;

  // Available VRAM in bytes (0 if CPU-only).
  int64 available_vram_bytes = 5;
}
