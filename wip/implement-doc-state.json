{
  "design_doc": "docs/designs/DESIGN-local-llm-runtime.md",
  "branch": "impl/local-llm-runtime-v2",
  "pr_number": 1810,
  "integrity_hash": "sha256:3c916544e328c5a8376dfd1f8eddc8701c656f9521c11df4889fb5d5b230fdfc",
  "issues": [
    {
      "number": 1628,
      "title": "feat(llm): complete local provider skeleton with lifecycle management",
      "status": "completed",
      "ci_status": "passed",
      "ci_fix_attempts": 0,
      "issue_type": "",
      "dependencies": [],
      "commits": [],
      "agent_type": "",
      "summary": null,
      "testable_scenarios": []
    },
    {
      "number": 1629,
      "title": "feat(llm): implement addon download and verification",
      "status": "completed",
      "ci_status": "passed",
      "ci_fix_attempts": 0,
      "issue_type": "",
      "dependencies": [
        1628
      ],
      "commits": [],
      "agent_type": "",
      "summary": null,
      "testable_scenarios": []
    },
    {
      "number": 1630,
      "title": "feat(llm): add configurable idle timeout",
      "status": "completed",
      "ci_status": "passed",
      "ci_fix_attempts": 0,
      "issue_type": "",
      "dependencies": [
        1628
      ],
      "commits": [],
      "agent_type": "",
      "summary": null,
      "testable_scenarios": []
    },
    {
      "number": 1631,
      "title": "feat(llm): implement SIGTERM handler for graceful shutdown",
      "status": "completed",
      "ci_status": "passed",
      "ci_fix_attempts": 0,
      "issue_type": "",
      "dependencies": [
        1628
      ],
      "commits": [],
      "agent_type": "",
      "summary": null,
      "testable_scenarios": []
    },
    {
      "number": 1632,
      "title": "feat(llm): integrate LocalProvider into factory with config",
      "status": "completed",
      "ci_status": "passed",
      "ci_fix_attempts": 0,
      "issue_type": "",
      "dependencies": [
        1628,
        1630
      ],
      "commits": [],
      "agent_type": "",
      "summary": null,
      "testable_scenarios": []
    },
    {
      "number": 1633,
      "title": "ci(llm): add Rust addon build pipeline",
      "status": "completed",
      "ci_status": "passed",
      "ci_fix_attempts": 0,
      "issue_type": "",
      "dependencies": [
        1628
      ],
      "commits": [],
      "agent_type": "",
      "summary": null,
      "testable_scenarios": []
    },
    {
      "number": 1634,
      "title": "test(llm): add lifecycle integration tests",
      "status": "completed",
      "ci_status": "passed",
      "ci_fix_attempts": 0,
      "issue_type": "",
      "dependencies": [
        1628,
        1630,
        1631
      ],
      "commits": [],
      "agent_type": "",
      "summary": null,
      "testable_scenarios": []
    },
    {
      "number": 1635,
      "title": "feat(llm): implement hardware detection",
      "status": "completed",
      "ci_status": "passed",
      "ci_fix_attempts": 0,
      "issue_type": "",
      "dependencies": [
        1628
      ],
      "commits": [],
      "agent_type": "",
      "summary": null,
      "testable_scenarios": []
    },
    {
      "number": 1636,
      "title": "feat(llm): implement model selection based on hardware",
      "status": "completed",
      "ci_status": "passed",
      "ci_fix_attempts": 0,
      "issue_type": "",
      "dependencies": [
        1635
      ],
      "commits": [],
      "agent_type": "",
      "summary": null,
      "testable_scenarios": []
    },
    {
      "number": 1637,
      "title": "feat(llm): implement model download with progress",
      "status": "completed",
      "ci_status": "passed",
      "ci_fix_attempts": 0,
      "issue_type": "",
      "dependencies": [
        1636
      ],
      "commits": [],
      "agent_type": "",
      "summary": null,
      "testable_scenarios": []
    },
    {
      "number": 1638,
      "title": "feat(llm): integrate llama.cpp for inference",
      "status": "completed",
      "ci_status": "passed",
      "ci_fix_attempts": 0,
      "issue_type": "",
      "dependencies": [
        1633,
        1637
      ],
      "commits": [],
      "agent_type": "",
      "summary": null,
      "testable_scenarios": []
    },
    {
      "number": 1672,
      "title": "feat(llm): configure model manifest with HuggingFace URLs",
      "status": "completed",
      "ci_status": "passed",
      "ci_fix_attempts": 0,
      "issue_type": "",
      "dependencies": [
        1637,
        1638
      ],
      "commits": [],
      "agent_type": "",
      "summary": null,
      "testable_scenarios": []
    },
    {
      "number": 1675,
      "title": "fix(llm): daemon socket not cleaned up on SIGTERM",
      "status": "completed",
      "ci_status": "passed",
      "ci_fix_attempts": 0,
      "issue_type": "",
      "dependencies": [
        1631
      ],
      "commits": [],
      "agent_type": "",
      "summary": null,
      "testable_scenarios": []
    },
    {
      "number": 1676,
      "title": "fix(llm): tokenization fails with negative count from llama_tokenize",
      "status": "completed",
      "ci_status": "passed",
      "ci_fix_attempts": 0,
      "issue_type": "",
      "dependencies": [
        1638
      ],
      "commits": [],
      "agent_type": "",
      "summary": null,
      "testable_scenarios": []
    },
    {
      "number": 1639,
      "title": "feat(llm): implement GBNF grammar constraints for JSON",
      "status": "completed",
      "ci_status": "passed",
      "ci_fix_attempts": 0,
      "issue_type": "",
      "dependencies": [
        1638
      ],
      "commits": [],
      "agent_type": "",
      "summary": null,
      "testable_scenarios": []
    },
    {
      "number": 1640,
      "title": "feat(llm): wire Complete RPC to llama.cpp inference",
      "status": "completed",
      "ci_status": "passed",
      "ci_fix_attempts": 0,
      "issue_type": "",
      "dependencies": [
        1639,
        1672,
        1675,
        1676
      ],
      "commits": [],
      "agent_type": "",
      "summary": null,
      "testable_scenarios": []
    },
    {
      "number": 1641,
      "title": "test(llm): add quality benchmark suite",
      "status": "completed",
      "ci_status": "passed",
      "ci_fix_attempts": 0,
      "issue_type": "code",
      "dependencies": [
        1640
      ],
      "commits": [
        "23b96e651d2d48c250482ef12d4b271d15d846ca"
      ],
      "agent_type": "coder",
      "summary": {
        "narrative": "",
        "files_changed": [
          "internal/builders/llm_integration_test.go",
          "internal/builders/baseline_test.go"
        ],
        "tests_added": 13,
        "key_decisions": "Extended existing TestLLMGroundTruth rather than creating new test files. Used BuildResult.RepairAttempts for repair tracking. Metrics logged in test output, not separate JSON.",
        "requirements_map": [
          {
            "ac": "latency metrics",
            "status": "implemented"
          },
          {
            "ac": "repair turn tracking",
            "status": "implemented"
          },
          {
            "ac": "configurable timeout",
            "status": "implemented"
          }
        ]
      },
      "reviewer_results": {
        "issue": 1641,
        "reviews": [
          {
            "focus": "pragmatic",
            "blocking_count": 0,
            "advisory_count": 3,
            "detail_file": "wip/research/implement-doc_review_pragmatic_issue1641.md"
          },
          {
            "focus": "architect",
            "blocking_count": 0,
            "advisory_count": 1,
            "detail_file": "wip/research/implement-doc_review_architect_issue1641.md"
          },
          {
            "focus": "maintainer",
            "blocking_count": 0,
            "advisory_count": 5,
            "detail_file": "wip/research/implement-doc_review_maintainer_issue1641.md"
          }
        ],
        "overall_blocking": 0,
        "verdict": "pass"
      },
      "testable_scenarios": [
        "scenario-1",
        "scenario-2",
        "scenario-3",
        "scenario-4"
      ]
    },
    {
      "number": 1642,
      "title": "feat(llm): add download permission prompts and progress UX",
      "status": "completed",
      "ci_status": "passed",
      "ci_fix_attempts": 0,
      "issue_type": "code",
      "dependencies": [
        1629,
        1637
      ],
      "commits": [
        "dc894884c6a2a4c6a062f76760317aa85d5ca002"
      ],
      "agent_type": "coder",
      "summary": {
        "narrative": "",
        "files_changed": [
          "internal/llm/addon/prompter.go",
          "internal/llm/addon/prompter_test.go",
          "internal/progress/spinner.go",
          "internal/progress/spinner_test.go",
          "internal/llm/addon/manager.go",
          "internal/llm/addon/manager_test.go",
          "internal/llm/factory.go",
          "internal/llm/local.go"
        ],
        "tests_added": 28,
        "key_decisions": "Prompter nil by default for backward compat. Model readiness via GetStatus RPC. Spinner writes to stderr. Factory WithPrompter option for clean wiring.",
        "requirements_map": [
          {
            "ac": "addon download prompt",
            "status": "implemented"
          },
          {
            "ac": "model download prompt",
            "status": "implemented"
          },
          {
            "ac": "decline with cloud provider message",
            "status": "implemented"
          },
          {
            "ac": "download progress bars",
            "status": "deviated",
            "reason": "addon downloads already use progress.Writer; model downloads inside Rust addon would need proto streaming changes"
          },
          {
            "ac": "inference spinner",
            "status": "implemented"
          },
          {
            "ac": "non-TTY suppression",
            "status": "implemented"
          },
          {
            "ac": "--yes flag skips prompts",
            "status": "implemented"
          }
        ]
      },
      "reviewer_results": {
        "issue": 1642,
        "reviews": [
          {
            "focus": "pragmatic",
            "blocking_count": 0,
            "advisory_count": 2,
            "detail_file": "wip/research/implement-doc_review_pragmatic_issue1642.md"
          },
          {
            "focus": "architect",
            "blocking_count": 0,
            "advisory_count": 2,
            "detail_file": "wip/research/implement-doc_review_architect_issue1642.md"
          },
          {
            "focus": "maintainer",
            "blocking_count": 0,
            "advisory_count": 6,
            "detail_file": "wip/research/implement-doc_review_maintainer_issue1642.md"
          }
        ],
        "overall_blocking": 0,
        "verdict": "pass"
      },
      "testable_scenarios": [
        "scenario-5",
        "scenario-6",
        "scenario-7",
        "scenario-8"
      ]
    },
    {
      "number": 1643,
      "title": "feat(llm): implement tsuku llm download command",
      "status": "completed",
      "ci_status": "passed",
      "ci_fix_attempts": 0,
      "issue_type": "code",
      "dependencies": [
        1629,
        1637
      ],
      "commits": [
        "c6117cbec0077365f7f7404875fca77fe6e44cbd"
      ],
      "agent_type": "coder",
      "summary": {
        "narrative": "",
        "files_changed": [
          "cmd/tsuku/llm.go",
          "cmd/tsuku/llm_test.go",
          "cmd/tsuku/main.go"
        ],
        "tests_added": 7,
        "key_decisions": "Reused existing AddonManager and ServerLifecycle APIs. Model download delegated to addon server. FormatSize reused from #1642. Exit code 2 deferred since gRPC has no model validation endpoint.",
        "requirements_map": [
          {
            "ac": "downloads addon binary",
            "status": "implemented"
          },
          {
            "ac": "hardware detection selects model",
            "status": "implemented"
          },
          {
            "ac": "model downloads with progress",
            "status": "implemented"
          },
          {
            "ac": "SHA256 verification",
            "status": "implemented"
          },
          {
            "ac": "--model flag overrides",
            "status": "implemented"
          },
          {
            "ac": "--force re-downloads",
            "status": "implemented"
          },
          {
            "ac": "exit 0 when cached",
            "status": "implemented"
          },
          {
            "ac": "exit 1 on failure",
            "status": "implemented"
          },
          {
            "ac": "exit 2 invalid model",
            "status": "deviated",
            "reason": "gRPC API lacks model validation endpoint"
          },
          {
            "ac": "works in CI",
            "status": "implemented"
          }
        ]
      },
      "reviewer_results": {
        "issue": 1643,
        "reviews": [
          {
            "focus": "pragmatic",
            "blocking_count": 1,
            "advisory_count": 3,
            "detail_file": "wip/research/implement-doc_review_pragmatic_issue1643.md",
            "note": "blocking finding (--force flag) addressed by removing flag"
          },
          {
            "focus": "architect",
            "blocking_count": 0,
            "advisory_count": 2,
            "detail_file": "wip/research/implement-doc_review_architect_issue1643.md"
          },
          {
            "focus": "maintainer",
            "blocking_count": 0,
            "advisory_count": 6,
            "detail_file": "wip/research/implement-doc_review_maintainer_issue1643.md"
          }
        ],
        "overall_blocking": 0,
        "verdict": "pass (after fix)"
      },
      "testable_scenarios": [
        "scenario-9",
        "scenario-10",
        "scenario-11",
        "scenario-12"
      ]
    },
    {
      "number": 1644,
      "title": "test(llm): add end-to-end integration test without cloud keys",
      "status": "scrutinized",
      "ci_status": "pending",
      "ci_fix_attempts": 0,
      "issue_type": "code",
      "dependencies": [
        1640,
        1632
      ],
      "commits": [
        "48f90a5944a38818e1862776cb9d8ad7bb81ea9c"
      ],
      "agent_type": "coder",
      "summary": {
        "narrative": "",
        "files_changed": [
          "internal/llm/local_e2e_test.go"
        ],
        "tests_added": 2,
        "key_decisions": "E2E build tag. Skip when addon not found. Factory fallback + Complete call. Validates tool call structure not TOML. CI workflow deferred.",
        "requirements_map": [
          {
            "ac": "test file exists",
            "status": "implemented"
          },
          {
            "ac": "factory fallback",
            "status": "implemented"
          },
          {
            "ac": "generates recipe",
            "status": "implemented"
          },
          {
            "ac": "TOML validation",
            "status": "deviated",
            "reason": "validates tool call structure at provider layer instead"
          },
          {
            "ac": "skips cleanly",
            "status": "implemented"
          },
          {
            "ac": "build tag",
            "status": "implemented"
          },
          {
            "ac": "CI workflow",
            "status": "deviated",
            "reason": "optional per issue, deferred"
          }
        ]
      },
      "testable_scenarios": [
        "scenario-13",
        "scenario-14"
      ]
    },
    {
      "number": 1645,
      "title": "docs(llm): update documentation for local inference",
      "status": "pending",
      "ci_status": "pending",
      "ci_fix_attempts": 0,
      "issue_type": "",
      "dependencies": [
        1632,
        1636
      ],
      "commits": [],
      "agent_type": "",
      "summary": null,
      "testable_scenarios": [
        "scenario-15",
        "scenario-16"
      ]
    }
  ],
  "skipped_issues": null,
  "test_plan_file": "wip/implement-doc_local-llm-runtime_test_plan.md"
}
