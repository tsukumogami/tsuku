// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.11
// 	protoc        v4.25.1
// source: llm.proto

package proto

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// Role indicates who authored a message.
type Role int32

const (
	Role_ROLE_UNSPECIFIED Role = 0
	Role_ROLE_USER        Role = 1
	Role_ROLE_ASSISTANT   Role = 2
	Role_ROLE_TOOL        Role = 3
)

// Enum value maps for Role.
var (
	Role_name = map[int32]string{
		0: "ROLE_UNSPECIFIED",
		1: "ROLE_USER",
		2: "ROLE_ASSISTANT",
		3: "ROLE_TOOL",
	}
	Role_value = map[string]int32{
		"ROLE_UNSPECIFIED": 0,
		"ROLE_USER":        1,
		"ROLE_ASSISTANT":   2,
		"ROLE_TOOL":        3,
	}
)

func (x Role) Enum() *Role {
	p := new(Role)
	*p = x
	return p
}

func (x Role) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Role) Descriptor() protoreflect.EnumDescriptor {
	return file_llm_proto_enumTypes[0].Descriptor()
}

func (Role) Type() protoreflect.EnumType {
	return &file_llm_proto_enumTypes[0]
}

func (x Role) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Role.Descriptor instead.
func (Role) EnumDescriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{0}
}

// CompletionRequest contains the input for an inference request.
type CompletionRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// System prompt providing context for the model.
	SystemPrompt string `protobuf:"bytes,1,opt,name=system_prompt,json=systemPrompt,proto3" json:"system_prompt,omitempty"`
	// Conversation history.
	Messages []*Message `protobuf:"bytes,2,rep,name=messages,proto3" json:"messages,omitempty"`
	// Available tools the model can call.
	Tools []*ToolDef `protobuf:"bytes,3,rep,name=tools,proto3" json:"tools,omitempty"`
	// Maximum tokens to generate.
	MaxTokens int32 `protobuf:"varint,4,opt,name=max_tokens,json=maxTokens,proto3" json:"max_tokens,omitempty"`
	// Optional JSON schema to constrain output format.
	// Used for structured extraction tasks.
	JsonSchema    string `protobuf:"bytes,5,opt,name=json_schema,json=jsonSchema,proto3" json:"json_schema,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CompletionRequest) Reset() {
	*x = CompletionRequest{}
	mi := &file_llm_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CompletionRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CompletionRequest) ProtoMessage() {}

func (x *CompletionRequest) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CompletionRequest.ProtoReflect.Descriptor instead.
func (*CompletionRequest) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{0}
}

func (x *CompletionRequest) GetSystemPrompt() string {
	if x != nil {
		return x.SystemPrompt
	}
	return ""
}

func (x *CompletionRequest) GetMessages() []*Message {
	if x != nil {
		return x.Messages
	}
	return nil
}

func (x *CompletionRequest) GetTools() []*ToolDef {
	if x != nil {
		return x.Tools
	}
	return nil
}

func (x *CompletionRequest) GetMaxTokens() int32 {
	if x != nil {
		return x.MaxTokens
	}
	return 0
}

func (x *CompletionRequest) GetJsonSchema() string {
	if x != nil {
		return x.JsonSchema
	}
	return ""
}

// CompletionResponse contains the model's output.
type CompletionResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Text content generated by the model.
	Content string `protobuf:"bytes,1,opt,name=content,proto3" json:"content,omitempty"`
	// Tool calls requested by the model.
	ToolCalls []*ToolCall `protobuf:"bytes,2,rep,name=tool_calls,json=toolCalls,proto3" json:"tool_calls,omitempty"`
	// Reason the model stopped generating.
	// Values: "end_turn", "tool_use", "max_tokens"
	StopReason string `protobuf:"bytes,3,opt,name=stop_reason,json=stopReason,proto3" json:"stop_reason,omitempty"`
	// Token usage statistics.
	Usage         *Usage `protobuf:"bytes,4,opt,name=usage,proto3" json:"usage,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CompletionResponse) Reset() {
	*x = CompletionResponse{}
	mi := &file_llm_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CompletionResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CompletionResponse) ProtoMessage() {}

func (x *CompletionResponse) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CompletionResponse.ProtoReflect.Descriptor instead.
func (*CompletionResponse) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{1}
}

func (x *CompletionResponse) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

func (x *CompletionResponse) GetToolCalls() []*ToolCall {
	if x != nil {
		return x.ToolCalls
	}
	return nil
}

func (x *CompletionResponse) GetStopReason() string {
	if x != nil {
		return x.StopReason
	}
	return ""
}

func (x *CompletionResponse) GetUsage() *Usage {
	if x != nil {
		return x.Usage
	}
	return nil
}

// Message represents a single turn in the conversation.
type Message struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Role of the message author.
	Role Role `protobuf:"varint,1,opt,name=role,proto3,enum=tsuku.llm.v1.Role" json:"role,omitempty"`
	// Text content of the message.
	Content string `protobuf:"bytes,2,opt,name=content,proto3" json:"content,omitempty"`
	// Tool calls made in this message (for assistant messages).
	ToolCalls []*ToolCall `protobuf:"bytes,3,rep,name=tool_calls,json=toolCalls,proto3" json:"tool_calls,omitempty"`
	// Tool result (for tool messages).
	ToolResult    *ToolResult `protobuf:"bytes,4,opt,name=tool_result,json=toolResult,proto3" json:"tool_result,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Message) Reset() {
	*x = Message{}
	mi := &file_llm_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Message) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Message) ProtoMessage() {}

func (x *Message) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Message.ProtoReflect.Descriptor instead.
func (*Message) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{2}
}

func (x *Message) GetRole() Role {
	if x != nil {
		return x.Role
	}
	return Role_ROLE_UNSPECIFIED
}

func (x *Message) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

func (x *Message) GetToolCalls() []*ToolCall {
	if x != nil {
		return x.ToolCalls
	}
	return nil
}

func (x *Message) GetToolResult() *ToolResult {
	if x != nil {
		return x.ToolResult
	}
	return nil
}

// ToolDef defines a tool available to the model.
type ToolDef struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Unique name of the tool.
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Human-readable description of what the tool does.
	Description string `protobuf:"bytes,2,opt,name=description,proto3" json:"description,omitempty"`
	// JSON Schema defining the tool's parameters.
	// Encoded as JSON string for flexibility.
	ParametersSchema string `protobuf:"bytes,3,opt,name=parameters_schema,json=parametersSchema,proto3" json:"parameters_schema,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *ToolDef) Reset() {
	*x = ToolDef{}
	mi := &file_llm_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ToolDef) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ToolDef) ProtoMessage() {}

func (x *ToolDef) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ToolDef.ProtoReflect.Descriptor instead.
func (*ToolDef) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{3}
}

func (x *ToolDef) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *ToolDef) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *ToolDef) GetParametersSchema() string {
	if x != nil {
		return x.ParametersSchema
	}
	return ""
}

// ToolCall represents a request from the model to invoke a tool.
type ToolCall struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Unique identifier for this tool call.
	Id string `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	// Name of the tool to invoke.
	Name string `protobuf:"bytes,2,opt,name=name,proto3" json:"name,omitempty"`
	// Arguments to pass to the tool, encoded as JSON.
	ArgumentsJson string `protobuf:"bytes,3,opt,name=arguments_json,json=argumentsJson,proto3" json:"arguments_json,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ToolCall) Reset() {
	*x = ToolCall{}
	mi := &file_llm_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ToolCall) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ToolCall) ProtoMessage() {}

func (x *ToolCall) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ToolCall.ProtoReflect.Descriptor instead.
func (*ToolCall) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{4}
}

func (x *ToolCall) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *ToolCall) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *ToolCall) GetArgumentsJson() string {
	if x != nil {
		return x.ArgumentsJson
	}
	return ""
}

// ToolResult contains the output from a tool invocation.
type ToolResult struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// ID of the tool call this result corresponds to.
	ToolCallId string `protobuf:"bytes,1,opt,name=tool_call_id,json=toolCallId,proto3" json:"tool_call_id,omitempty"`
	// Output from the tool, typically as string or JSON.
	Content string `protobuf:"bytes,2,opt,name=content,proto3" json:"content,omitempty"`
	// Whether the tool invocation failed.
	IsError       bool `protobuf:"varint,3,opt,name=is_error,json=isError,proto3" json:"is_error,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ToolResult) Reset() {
	*x = ToolResult{}
	mi := &file_llm_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ToolResult) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ToolResult) ProtoMessage() {}

func (x *ToolResult) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ToolResult.ProtoReflect.Descriptor instead.
func (*ToolResult) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{5}
}

func (x *ToolResult) GetToolCallId() string {
	if x != nil {
		return x.ToolCallId
	}
	return ""
}

func (x *ToolResult) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

func (x *ToolResult) GetIsError() bool {
	if x != nil {
		return x.IsError
	}
	return false
}

// Usage tracks token consumption for billing/monitoring.
type Usage struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Number of tokens in the input (prompt + history).
	InputTokens int32 `protobuf:"varint,1,opt,name=input_tokens,json=inputTokens,proto3" json:"input_tokens,omitempty"`
	// Number of tokens generated.
	OutputTokens  int32 `protobuf:"varint,2,opt,name=output_tokens,json=outputTokens,proto3" json:"output_tokens,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Usage) Reset() {
	*x = Usage{}
	mi := &file_llm_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Usage) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Usage) ProtoMessage() {}

func (x *Usage) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Usage.ProtoReflect.Descriptor instead.
func (*Usage) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{6}
}

func (x *Usage) GetInputTokens() int32 {
	if x != nil {
		return x.InputTokens
	}
	return 0
}

func (x *Usage) GetOutputTokens() int32 {
	if x != nil {
		return x.OutputTokens
	}
	return 0
}

// ShutdownRequest signals the server to terminate.
type ShutdownRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// If true, wait for any in-flight requests to complete.
	Graceful      bool `protobuf:"varint,1,opt,name=graceful,proto3" json:"graceful,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ShutdownRequest) Reset() {
	*x = ShutdownRequest{}
	mi := &file_llm_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ShutdownRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ShutdownRequest) ProtoMessage() {}

func (x *ShutdownRequest) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ShutdownRequest.ProtoReflect.Descriptor instead.
func (*ShutdownRequest) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{7}
}

func (x *ShutdownRequest) GetGraceful() bool {
	if x != nil {
		return x.Graceful
	}
	return false
}

// ShutdownResponse acknowledges shutdown initiation.
type ShutdownResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// True if shutdown was accepted.
	Accepted      bool `protobuf:"varint,1,opt,name=accepted,proto3" json:"accepted,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ShutdownResponse) Reset() {
	*x = ShutdownResponse{}
	mi := &file_llm_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ShutdownResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ShutdownResponse) ProtoMessage() {}

func (x *ShutdownResponse) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ShutdownResponse.ProtoReflect.Descriptor instead.
func (*ShutdownResponse) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{8}
}

func (x *ShutdownResponse) GetAccepted() bool {
	if x != nil {
		return x.Accepted
	}
	return false
}

// StatusRequest queries the server's current state.
type StatusRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StatusRequest) Reset() {
	*x = StatusRequest{}
	mi := &file_llm_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StatusRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StatusRequest) ProtoMessage() {}

func (x *StatusRequest) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StatusRequest.ProtoReflect.Descriptor instead.
func (*StatusRequest) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{9}
}

// StatusResponse provides server health and model information.
type StatusResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Whether the server is ready to accept requests.
	Ready bool `protobuf:"varint,1,opt,name=ready,proto3" json:"ready,omitempty"`
	// Currently loaded model name (e.g., "qwen2.5-1.5b-q4_k_m").
	ModelName string `protobuf:"bytes,2,opt,name=model_name,json=modelName,proto3" json:"model_name,omitempty"`
	// Model file size in bytes.
	ModelSizeBytes int64 `protobuf:"varint,3,opt,name=model_size_bytes,json=modelSizeBytes,proto3" json:"model_size_bytes,omitempty"`
	// Hardware backend in use (e.g., "cuda", "metal", "cpu").
	Backend string `protobuf:"bytes,4,opt,name=backend,proto3" json:"backend,omitempty"`
	// Available VRAM in bytes (0 if CPU-only).
	AvailableVramBytes int64 `protobuf:"varint,5,opt,name=available_vram_bytes,json=availableVramBytes,proto3" json:"available_vram_bytes,omitempty"`
	unknownFields      protoimpl.UnknownFields
	sizeCache          protoimpl.SizeCache
}

func (x *StatusResponse) Reset() {
	*x = StatusResponse{}
	mi := &file_llm_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StatusResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StatusResponse) ProtoMessage() {}

func (x *StatusResponse) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StatusResponse.ProtoReflect.Descriptor instead.
func (*StatusResponse) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{10}
}

func (x *StatusResponse) GetReady() bool {
	if x != nil {
		return x.Ready
	}
	return false
}

func (x *StatusResponse) GetModelName() string {
	if x != nil {
		return x.ModelName
	}
	return ""
}

func (x *StatusResponse) GetModelSizeBytes() int64 {
	if x != nil {
		return x.ModelSizeBytes
	}
	return 0
}

func (x *StatusResponse) GetBackend() string {
	if x != nil {
		return x.Backend
	}
	return ""
}

func (x *StatusResponse) GetAvailableVramBytes() int64 {
	if x != nil {
		return x.AvailableVramBytes
	}
	return 0
}

var File_llm_proto protoreflect.FileDescriptor

const file_llm_proto_rawDesc = "" +
	"\n" +
	"\tllm.proto\x12\ftsuku.llm.v1\"\xd8\x01\n" +
	"\x11CompletionRequest\x12#\n" +
	"\rsystem_prompt\x18\x01 \x01(\tR\fsystemPrompt\x121\n" +
	"\bmessages\x18\x02 \x03(\v2\x15.tsuku.llm.v1.MessageR\bmessages\x12+\n" +
	"\x05tools\x18\x03 \x03(\v2\x15.tsuku.llm.v1.ToolDefR\x05tools\x12\x1d\n" +
	"\n" +
	"max_tokens\x18\x04 \x01(\x05R\tmaxTokens\x12\x1f\n" +
	"\vjson_schema\x18\x05 \x01(\tR\n" +
	"jsonSchema\"\xb1\x01\n" +
	"\x12CompletionResponse\x12\x18\n" +
	"\acontent\x18\x01 \x01(\tR\acontent\x125\n" +
	"\n" +
	"tool_calls\x18\x02 \x03(\v2\x16.tsuku.llm.v1.ToolCallR\ttoolCalls\x12\x1f\n" +
	"\vstop_reason\x18\x03 \x01(\tR\n" +
	"stopReason\x12)\n" +
	"\x05usage\x18\x04 \x01(\v2\x13.tsuku.llm.v1.UsageR\x05usage\"\xbd\x01\n" +
	"\aMessage\x12&\n" +
	"\x04role\x18\x01 \x01(\x0e2\x12.tsuku.llm.v1.RoleR\x04role\x12\x18\n" +
	"\acontent\x18\x02 \x01(\tR\acontent\x125\n" +
	"\n" +
	"tool_calls\x18\x03 \x03(\v2\x16.tsuku.llm.v1.ToolCallR\ttoolCalls\x129\n" +
	"\vtool_result\x18\x04 \x01(\v2\x18.tsuku.llm.v1.ToolResultR\n" +
	"toolResult\"l\n" +
	"\aToolDef\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12 \n" +
	"\vdescription\x18\x02 \x01(\tR\vdescription\x12+\n" +
	"\x11parameters_schema\x18\x03 \x01(\tR\x10parametersSchema\"U\n" +
	"\bToolCall\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\x12\x12\n" +
	"\x04name\x18\x02 \x01(\tR\x04name\x12%\n" +
	"\x0earguments_json\x18\x03 \x01(\tR\rargumentsJson\"c\n" +
	"\n" +
	"ToolResult\x12 \n" +
	"\ftool_call_id\x18\x01 \x01(\tR\n" +
	"toolCallId\x12\x18\n" +
	"\acontent\x18\x02 \x01(\tR\acontent\x12\x19\n" +
	"\bis_error\x18\x03 \x01(\bR\aisError\"O\n" +
	"\x05Usage\x12!\n" +
	"\finput_tokens\x18\x01 \x01(\x05R\vinputTokens\x12#\n" +
	"\routput_tokens\x18\x02 \x01(\x05R\foutputTokens\"-\n" +
	"\x0fShutdownRequest\x12\x1a\n" +
	"\bgraceful\x18\x01 \x01(\bR\bgraceful\".\n" +
	"\x10ShutdownResponse\x12\x1a\n" +
	"\baccepted\x18\x01 \x01(\bR\baccepted\"\x0f\n" +
	"\rStatusRequest\"\xbb\x01\n" +
	"\x0eStatusResponse\x12\x14\n" +
	"\x05ready\x18\x01 \x01(\bR\x05ready\x12\x1d\n" +
	"\n" +
	"model_name\x18\x02 \x01(\tR\tmodelName\x12(\n" +
	"\x10model_size_bytes\x18\x03 \x01(\x03R\x0emodelSizeBytes\x12\x18\n" +
	"\abackend\x18\x04 \x01(\tR\abackend\x120\n" +
	"\x14available_vram_bytes\x18\x05 \x01(\x03R\x12availableVramBytes*N\n" +
	"\x04Role\x12\x14\n" +
	"\x10ROLE_UNSPECIFIED\x10\x00\x12\r\n" +
	"\tROLE_USER\x10\x01\x12\x12\n" +
	"\x0eROLE_ASSISTANT\x10\x02\x12\r\n" +
	"\tROLE_TOOL\x10\x032\xf4\x01\n" +
	"\x10InferenceService\x12M\n" +
	"\bComplete\x12\x1f.tsuku.llm.v1.CompletionRequest\x1a .tsuku.llm.v1.CompletionResponse\x12I\n" +
	"\bShutdown\x12\x1d.tsuku.llm.v1.ShutdownRequest\x1a\x1e.tsuku.llm.v1.ShutdownResponse\x12F\n" +
	"\tGetStatus\x12\x1b.tsuku.llm.v1.StatusRequest\x1a\x1c.tsuku.llm.v1.StatusResponseB1Z/github.com/tsukumogami/tsuku/internal/llm/protob\x06proto3"

var (
	file_llm_proto_rawDescOnce sync.Once
	file_llm_proto_rawDescData []byte
)

func file_llm_proto_rawDescGZIP() []byte {
	file_llm_proto_rawDescOnce.Do(func() {
		file_llm_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_llm_proto_rawDesc), len(file_llm_proto_rawDesc)))
	})
	return file_llm_proto_rawDescData
}

var file_llm_proto_enumTypes = make([]protoimpl.EnumInfo, 1)
var file_llm_proto_msgTypes = make([]protoimpl.MessageInfo, 11)
var file_llm_proto_goTypes = []any{
	(Role)(0),                  // 0: tsuku.llm.v1.Role
	(*CompletionRequest)(nil),  // 1: tsuku.llm.v1.CompletionRequest
	(*CompletionResponse)(nil), // 2: tsuku.llm.v1.CompletionResponse
	(*Message)(nil),            // 3: tsuku.llm.v1.Message
	(*ToolDef)(nil),            // 4: tsuku.llm.v1.ToolDef
	(*ToolCall)(nil),           // 5: tsuku.llm.v1.ToolCall
	(*ToolResult)(nil),         // 6: tsuku.llm.v1.ToolResult
	(*Usage)(nil),              // 7: tsuku.llm.v1.Usage
	(*ShutdownRequest)(nil),    // 8: tsuku.llm.v1.ShutdownRequest
	(*ShutdownResponse)(nil),   // 9: tsuku.llm.v1.ShutdownResponse
	(*StatusRequest)(nil),      // 10: tsuku.llm.v1.StatusRequest
	(*StatusResponse)(nil),     // 11: tsuku.llm.v1.StatusResponse
}
var file_llm_proto_depIdxs = []int32{
	3,  // 0: tsuku.llm.v1.CompletionRequest.messages:type_name -> tsuku.llm.v1.Message
	4,  // 1: tsuku.llm.v1.CompletionRequest.tools:type_name -> tsuku.llm.v1.ToolDef
	5,  // 2: tsuku.llm.v1.CompletionResponse.tool_calls:type_name -> tsuku.llm.v1.ToolCall
	7,  // 3: tsuku.llm.v1.CompletionResponse.usage:type_name -> tsuku.llm.v1.Usage
	0,  // 4: tsuku.llm.v1.Message.role:type_name -> tsuku.llm.v1.Role
	5,  // 5: tsuku.llm.v1.Message.tool_calls:type_name -> tsuku.llm.v1.ToolCall
	6,  // 6: tsuku.llm.v1.Message.tool_result:type_name -> tsuku.llm.v1.ToolResult
	1,  // 7: tsuku.llm.v1.InferenceService.Complete:input_type -> tsuku.llm.v1.CompletionRequest
	8,  // 8: tsuku.llm.v1.InferenceService.Shutdown:input_type -> tsuku.llm.v1.ShutdownRequest
	10, // 9: tsuku.llm.v1.InferenceService.GetStatus:input_type -> tsuku.llm.v1.StatusRequest
	2,  // 10: tsuku.llm.v1.InferenceService.Complete:output_type -> tsuku.llm.v1.CompletionResponse
	9,  // 11: tsuku.llm.v1.InferenceService.Shutdown:output_type -> tsuku.llm.v1.ShutdownResponse
	11, // 12: tsuku.llm.v1.InferenceService.GetStatus:output_type -> tsuku.llm.v1.StatusResponse
	10, // [10:13] is the sub-list for method output_type
	7,  // [7:10] is the sub-list for method input_type
	7,  // [7:7] is the sub-list for extension type_name
	7,  // [7:7] is the sub-list for extension extendee
	0,  // [0:7] is the sub-list for field type_name
}

func init() { file_llm_proto_init() }
func file_llm_proto_init() {
	if File_llm_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_llm_proto_rawDesc), len(file_llm_proto_rawDesc)),
			NumEnums:      1,
			NumMessages:   11,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_llm_proto_goTypes,
		DependencyIndexes: file_llm_proto_depIdxs,
		EnumInfos:         file_llm_proto_enumTypes,
		MessageInfos:      file_llm_proto_msgTypes,
	}.Build()
	File_llm_proto = out.File
	file_llm_proto_goTypes = nil
	file_llm_proto_depIdxs = nil
}
