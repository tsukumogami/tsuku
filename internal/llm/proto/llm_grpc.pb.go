// Code generated by protoc-gen-go-grpc. DO NOT EDIT.
// versions:
// - protoc-gen-go-grpc v1.6.1
// - protoc             v4.25.1
// source: llm.proto

package proto

import (
	context "context"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
)

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
// Requires gRPC-Go v1.64.0 or later.
const _ = grpc.SupportPackageIsVersion9

const (
	InferenceService_Complete_FullMethodName  = "/tsuku.llm.v1.InferenceService/Complete"
	InferenceService_Shutdown_FullMethodName  = "/tsuku.llm.v1.InferenceService/Shutdown"
	InferenceService_GetStatus_FullMethodName = "/tsuku.llm.v1.InferenceService/GetStatus"
)

// InferenceServiceClient is the client API for InferenceService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
//
// InferenceService provides local LLM inference capabilities.
// The server runs as a separate process (tsuku-llm) and communicates
// over Unix domain sockets.
type InferenceServiceClient interface {
	// Complete generates a completion for the given request.
	// Supports tool calling for structured extraction tasks.
	Complete(ctx context.Context, in *CompletionRequest, opts ...grpc.CallOption) (*CompletionResponse, error)
	// Shutdown gracefully terminates the inference server.
	// Called when tsuku exits or when idle timeout is reached.
	Shutdown(ctx context.Context, in *ShutdownRequest, opts ...grpc.CallOption) (*ShutdownResponse, error)
	// GetStatus returns the current server status including loaded model info.
	GetStatus(ctx context.Context, in *StatusRequest, opts ...grpc.CallOption) (*StatusResponse, error)
}

type inferenceServiceClient struct {
	cc grpc.ClientConnInterface
}

func NewInferenceServiceClient(cc grpc.ClientConnInterface) InferenceServiceClient {
	return &inferenceServiceClient{cc}
}

func (c *inferenceServiceClient) Complete(ctx context.Context, in *CompletionRequest, opts ...grpc.CallOption) (*CompletionResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(CompletionResponse)
	err := c.cc.Invoke(ctx, InferenceService_Complete_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *inferenceServiceClient) Shutdown(ctx context.Context, in *ShutdownRequest, opts ...grpc.CallOption) (*ShutdownResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(ShutdownResponse)
	err := c.cc.Invoke(ctx, InferenceService_Shutdown_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *inferenceServiceClient) GetStatus(ctx context.Context, in *StatusRequest, opts ...grpc.CallOption) (*StatusResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(StatusResponse)
	err := c.cc.Invoke(ctx, InferenceService_GetStatus_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// InferenceServiceServer is the server API for InferenceService service.
// All implementations must embed UnimplementedInferenceServiceServer
// for forward compatibility.
//
// InferenceService provides local LLM inference capabilities.
// The server runs as a separate process (tsuku-llm) and communicates
// over Unix domain sockets.
type InferenceServiceServer interface {
	// Complete generates a completion for the given request.
	// Supports tool calling for structured extraction tasks.
	Complete(context.Context, *CompletionRequest) (*CompletionResponse, error)
	// Shutdown gracefully terminates the inference server.
	// Called when tsuku exits or when idle timeout is reached.
	Shutdown(context.Context, *ShutdownRequest) (*ShutdownResponse, error)
	// GetStatus returns the current server status including loaded model info.
	GetStatus(context.Context, *StatusRequest) (*StatusResponse, error)
	mustEmbedUnimplementedInferenceServiceServer()
}

// UnimplementedInferenceServiceServer must be embedded to have
// forward compatible implementations.
//
// NOTE: this should be embedded by value instead of pointer to avoid a nil
// pointer dereference when methods are called.
type UnimplementedInferenceServiceServer struct{}

func (UnimplementedInferenceServiceServer) Complete(context.Context, *CompletionRequest) (*CompletionResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method Complete not implemented")
}
func (UnimplementedInferenceServiceServer) Shutdown(context.Context, *ShutdownRequest) (*ShutdownResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method Shutdown not implemented")
}
func (UnimplementedInferenceServiceServer) GetStatus(context.Context, *StatusRequest) (*StatusResponse, error) {
	return nil, status.Error(codes.Unimplemented, "method GetStatus not implemented")
}
func (UnimplementedInferenceServiceServer) mustEmbedUnimplementedInferenceServiceServer() {}
func (UnimplementedInferenceServiceServer) testEmbeddedByValue()                          {}

// UnsafeInferenceServiceServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to InferenceServiceServer will
// result in compilation errors.
type UnsafeInferenceServiceServer interface {
	mustEmbedUnimplementedInferenceServiceServer()
}

func RegisterInferenceServiceServer(s grpc.ServiceRegistrar, srv InferenceServiceServer) {
	// If the following call panics, it indicates UnimplementedInferenceServiceServer was
	// embedded by pointer and is nil.  This will cause panics if an
	// unimplemented method is ever invoked, so we test this at initialization
	// time to prevent it from happening at runtime later due to I/O.
	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
		t.testEmbeddedByValue()
	}
	s.RegisterService(&InferenceService_ServiceDesc, srv)
}

func _InferenceService_Complete_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(CompletionRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(InferenceServiceServer).Complete(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: InferenceService_Complete_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(InferenceServiceServer).Complete(ctx, req.(*CompletionRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _InferenceService_Shutdown_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ShutdownRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(InferenceServiceServer).Shutdown(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: InferenceService_Shutdown_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(InferenceServiceServer).Shutdown(ctx, req.(*ShutdownRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _InferenceService_GetStatus_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(StatusRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(InferenceServiceServer).GetStatus(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: InferenceService_GetStatus_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(InferenceServiceServer).GetStatus(ctx, req.(*StatusRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// InferenceService_ServiceDesc is the grpc.ServiceDesc for InferenceService service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var InferenceService_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "tsuku.llm.v1.InferenceService",
	HandlerType: (*InferenceServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "Complete",
			Handler:    _InferenceService_Complete_Handler,
		},
		{
			MethodName: "Shutdown",
			Handler:    _InferenceService_Shutdown_Handler,
		},
		{
			MethodName: "GetStatus",
			Handler:    _InferenceService_GetStatus_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "llm.proto",
}
